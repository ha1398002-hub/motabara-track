import streamlit as st
import tempfile, os
from pydub import AudioSegment

st.set_page_config(page_title="Ù…Ø«Ø§Ø¨Ø±Ø© ØªØ±Ø§Ùƒ", layout="wide")
st.title("ğŸ¤ Ù…Ø«Ø§Ø¨Ø±Ø© ØªØ±Ø§Ùƒ â€” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø·Ù‚")

st.markdown("Ø§Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØªÙŠ (mp3 / wav / m4a). Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø³ÙŠØ­ÙˆÙ‘Ù„Ù‡ Ù„ØµÙŠØºØ© wav Ø«Ù… ÙŠØ­Ø§ÙˆÙ„ ØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ Ù†Øµ ÙˆØªØ­Ù„ÙŠÙ„Ù‡.")

uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØªÙŠ Ù‡Ù†Ø§", type=["wav", "mp3", "m4a", "amr"])

def analyze_text_and_segments(text, segments):
    issues = []
    # ØªÙƒØ±Ø§Ø± ÙƒÙ„Ù…Ø§Øª Ù…ØªØªØ§Ø¨Ø¹Ø©
    words = text.split()
    for i in range(1, len(words)):
        if words[i] == words[i-1]:
            issues.append(f"ØªÙƒØ±Ø§Ø± ÙƒÙ„Ù…Ø© Ù…ØªØªØ§Ø¨Ø¹Ø©: Â«{words[i]}Â»")

    # ØªÙˆÙ‚ÙØ§Øª Ø·ÙˆÙŠÙ„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù€ segments (Ù„Ùˆ Ù…ØªØ§Ø­)
    try:
        prev_end = None
        for s in segments:
            start = getattr(s, "start", s.get("start") if isinstance(s, dict) else None)
            end = getattr(s, "end", s.get("end") if isinstance(s, dict) else None)
            if prev_end is not None and start is not None:
                silence = start - prev_end
                if silence > 1.5:
                    issues.append(f"ÙˆÙ‚ÙØ© Ø·ÙˆÙŠÙ„Ø© Ù‚Ø¨Ù„ Ø¬Ø²Ø¡ Ø¹Ù†Ø¯ {start:.2f}s (Ù…Ø¯Ø© {silence:.2f}s)")
            prev_end = end
    except Exception:
        pass

    # Ù„ÙØ¯ØºØ§Øª / Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ø§Øª ØªÙ‚Ø±ÙŠØ¨ÙŠØ© (ØªØ­Ù„ÙŠÙ„ Ø¨Ø³ÙŠØ· Ù†ØµÙŠ)
    if "Ø«" in text and "Ø³" not in text:
        issues.append("Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø³ÙŠÙ† Ø¨Ø§Ù„Ø«Ø§Ø¡")
    if "Ø´" in text and "Ø³" not in text:
        issues.append("Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø³ÙŠÙ† Ø¨Ø§Ù„Ø´ÙŠÙ†")
    if "ÙŠ" in text and "Ø±" not in text:
        issues.append("Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø±Ø§Ø¡ Ø¨Ø§Ù„ÙŠØ§Ø¡")
    if "Ù„" in text and "Ø±" not in text:
        issues.append("Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø±Ø§Ø¡ Ø¨Ø§Ù„Ù„Ø§Ù…")
    if "Øº" in text and "Ø±" not in text:
        issues.append("Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø±Ø§Ø¡ Ø¨Ø§Ù„ØºÙŠÙ†")

    # ØªÙ„Ø¹Ø«Ù… Ø­Ø±ÙÙŠ: ØªÙƒØ±Ø§Ø± Ù†ÙØ³ Ø§Ù„Ø­Ø±Ù Ø¯Ø§Ø®Ù„ Ø§Ù„ÙƒÙ„Ù…Ø© (Ù…Ø«Ø§Ù„: Ù…Ù€Ù…Ù€Ù…)
    for w in words:
        for ch in set(w):
            if w.count(ch) >= 3:
                issues.append(f"ØªÙ„Ø¹Ø«Ù…/ØªÙƒØ±Ø§Ø± Ø­Ø±ÙÙŠ Ø¯Ø§Ø®Ù„ ÙƒÙ„Ù…Ø©: Â«{w}Â» (Ø§Ù„Ø­Ø±Ù Â«{ch}Â» ØªÙƒØ±Ø±)")

    return issues

if uploaded_file:
    # Ø­ÙØ¸ Ù…Ø¤Ù‚Øª Ù„Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø±ÙÙˆØ¹
    suffix = os.path.splitext(uploaded_file.name)[1]
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp.write(uploaded_file.read())
        tmp_path = tmp.name

    st.success(f"ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù: {uploaded_file.name}")
    st.audio(tmp_path)

    # Ù†Ø­Ø§ÙˆÙ„ ØªØ­ÙˆÙŠÙ„ Ø£ÙŠ ØµÙŠØºØ© Ø¥Ù„Ù‰ WAV (PCM) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pydub/ffmpeg
    wav_path = tmp_path + ".wav"
    try:
        AudioSegment.from_file(tmp_path).export(wav_path, format="wav")
    except Exception as e:
        st.error("Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ WAV: " + str(e))
        os.remove(tmp_path)
        st.stop()

    st.info("â³ Ø¬Ø§Ø±ÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ (Ù…Ø­Ø§ÙˆÙ„Ø© Ø³Ø±ÙŠØ¹Ø©)...")

    text = None
    segments = []

    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… faster-whisper Ø£ÙˆÙ„Ø§Ù‹ (Ù„Ùˆ Ù…ØªØ§Ø­Ø©)
    try:
        from faster_whisper import WhisperModel
        model = WhisperModel("small", device="cpu", compute_type="int8")
        segments_obj, info = model.transcribe(wav_path, beam_size=5)
        # Ù†Ø¬Ù…Ø¹ Ø§Ù„Ù†Øµ ÙˆÙ†Ø­ØªÙØ¸ Ø¨Ø§Ù„Ù€ segments
        text = " ".join([seg.text.strip() for seg in segments_obj]).strip()
        # Ù†Ø­ÙˆÙ„ segments_obj Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© dict Ø¨Ø³ÙŠØ·Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
        for seg in segments_obj:
            segments.append({"start": float(seg.start), "end": float(seg.end), "text": seg.text})
    except Exception as e_fw:
        st.warning("faster-whisper ØºÙŠØ± Ù…ØªØ§Ø­ Ø£Ùˆ ÙØ´Ù„ (Ø³ÙŠÙØ­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø±ÙŠÙ‚Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©).")
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¯ÙŠÙ„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… SpeechRecognition + Google (Ù‚Ø¯ ÙŠÙ†Ø¬Ø­ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø­Ø§Ø¨Ø©)
        try:
            import speech_recognition as sr
            r = sr.Recognizer()
            with sr.AudioFile(wav_path) as source:
                audio_data = r.record(source)
                text = r.recognize_google(audio_data, language="ar-EG")
                segments = [{"start": 0.0, "end": 0.0, "text": text}]
        except Exception as e_sr:
            st.error("Ù„Ù… Ø£Ø³ØªØ·Ø¹ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ù„Ù†Øµ Ù‡Ù†Ø§:\n" + str(e_sr))

    if text:
        st.subheader("ğŸ“„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø­ÙˆÙ‘Ù„:")
        st.write(text)

        st.subheader("ğŸ” Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„:")
        issues = analyze_text_and_segments(text, segments)
        if issues:
            for it in issues:
                st.warning(it)
        else:
            st.success("Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù Ù…Ø´Ø§ÙƒÙ„ ÙˆØ§Ø¶Ø­Ø© ÙÙŠ Ø§Ù„Ù†Øµ.")

    # ØªÙ†Ø¸ÙŠÙ Ù…Ù„ÙØ§Øª Ù…Ø¤Ù‚ØªØ©
    try:
        os.remove(tmp_path)
        if os.path.exists(wav_path):
            os.remove(wav_path)
    except:
        pass
