import streamlit as st
from faster_whisper import WhisperModel
import tempfile

st.title("ØªØ·Ø¨ÙŠÙ‚ Ù…Ø«Ø§Ø¨Ø±Ø© ØªØ±Ø§Ùƒ ğŸ¤")
st.write("Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… ÙˆØ±Ø­Ù…Ø© Ø§Ù„Ù„Ù‡ ÙˆØ¨Ø±ÙƒØ§ØªØ© ğŸ‘‹ØŒ Streamlit")

uploaded_file = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØªÙŠ", type=["wav", "mp3", "m4a", "ogg"])

if uploaded_file is not None:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
        tmp.write(uploaded_file.read())
        temp_wav = tmp.name

    # ØªÙØ±ÙŠØº Ø§Ù„ÙƒÙ„Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Whisper
    model = WhisperModel("base", device="cpu", compute_type="int8")
    segments, _ = model.transcribe(temp_wav, beam_size=5)

    text = " ".join([segment.text for segment in segments])
    st.subheader("ğŸ“ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙƒØªØ´Ù:")
    st.write(text)

    # ÙƒØ´Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¨Ø³ÙŠØ·Ø© (Ø¨Ø¯Ù„ Ø§Ù„Ø­Ø±ÙˆÙ)
    mistakes = []
    if "Ø«" in text:
        mistakes.append("ØªÙ… Ù†Ø·Ù‚ Ø§Ù„Ø³ÙŠÙ† ÙƒØ«Ø§Ø¡ (Ø« Ø¨Ø¯Ù„ Ø³)")
    if "Ø´" in text:
        mistakes.append("ØªÙ… Ù†Ø·Ù‚ Ø§Ù„Ø³ÙŠÙ† ÙƒÙ€ Ø´")
    if "ÙŠ" in text or "Ù„" in text:
        mistakes.append("Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø±Ø§Ø¡ (Ø±) Ø¨Ù€ ÙŠ/Ù„")
    if "Øº" in text:
        mistakes.append("Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø±Ø§Ø¡ (Ø±) Ø¨Ù€ Øº")

    if mistakes:
        st.subheader("ğŸš¨ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø·Ù‚:")
        for m in mistakes:
            st.write("- " + m)

    # ğŸ”¹ ÙƒØ´Ù Ø§Ù„ØªÙˆÙ‚ÙØ§Øª (Ø§Ù„ØµÙ…Øª)
    # silent_ranges = silence.detect_silence(audio, min_silence_len=700, silence_thresh=audio.dBFS-16)

      
            
    else:
        st.write("âœ… Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªÙˆÙ‚ÙØ§Øª Ø·ÙˆÙŠÙ„Ø© Ù…Ù„Ø­ÙˆØ¸Ø©.")
